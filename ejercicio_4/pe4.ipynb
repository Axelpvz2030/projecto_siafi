{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "18Ny-h2FKB9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc0af1e-100c-4d7c-b88c-8e7fa62fd3b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1182/1182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8511 - loss: 0.5185 - val_accuracy: 0.9500 - val_loss: 0.1607\n",
            "Epoch 2/5\n",
            "\u001b[1m1182/1182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9605 - loss: 0.1339 - val_accuracy: 0.9595 - val_loss: 0.1313\n",
            "Epoch 3/5\n",
            "\u001b[1m1182/1182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9736 - loss: 0.0821 - val_accuracy: 0.9643 - val_loss: 0.1031\n",
            "Epoch 4/5\n",
            "\u001b[1m1182/1182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.0618 - val_accuracy: 0.9676 - val_loss: 0.1019\n",
            "Epoch 5/5\n",
            "\u001b[1m1182/1182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0474 - val_accuracy: 0.9681 - val_loss: 0.1039\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.0995\n",
            "\n",
            "Precisión en prueba: 0.9698\n",
            "\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9910    0.9740    0.9824      1805\n",
            "           1     0.9860    0.9855    0.9857      1994\n",
            "           2     0.9551    0.9795    0.9672      1759\n",
            "           3     0.9734    0.9529    0.9630      1846\n",
            "           4     0.9757    0.9762    0.9760      1726\n",
            "           5     0.9735    0.9552    0.9643      1653\n",
            "           6     0.9805    0.9843    0.9824      1787\n",
            "           7     0.9518    0.9793    0.9654      1937\n",
            "           8     0.9310    0.9751    0.9526      1730\n",
            "           9     0.9821    0.9325    0.9566      1763\n",
            "\n",
            "    accuracy                         0.9698     18000\n",
            "   macro avg     0.9700    0.9695    0.9696     18000\n",
            "weighted avg     0.9702    0.9698    0.9698     18000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "(x, y), _ = tf.keras.datasets.mnist.load_data()\n",
        "x_reshaped = x.reshape(-1, 28 * 28)\n",
        "scaler = MinMaxScaler()\n",
        "x_scaled = scaler.fit_transform(x_reshaped)\n",
        "x_scaled = x_scaled.reshape(-1, 28, 28)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(28, 28)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'\\nPrecisión en prueba: {test_accuracy:.4f}')\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_classes = tf.argmax(y_pred, axis=1).numpy()\n",
        "\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred_classes, digits=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este ejercicio decidi ir con el mnist de keras que incluye imagenes de numeros y sus etiquetas, al ser un ejemplo sencillo. La eleccion de el numero de capaz y funciones de activacion y error fueron segun lo que encontre es lo estandar para este caso, un problema de clasificaicon, primero la primer neurona recibe la imagen de 28*28 pixeles que es aplanada en un vector de 784 variables, cada pixel siendo una. De aqui se pasa  ala primer capa, con 128 neuronas, la eleccion de este numero se debe a 2 razones, la primera, las GPU tienden a estar mejor optimizadas cuando se usa un numero de neuronas multiplo, de , y 128 funciona como un buen punto medio inicial, menos neuronas haria que no se pueda captar dettales mas complejos, mientras que mas podria provocar overfitting. En cuanto a la funcion se fue con relu, funcion que simplemente cambia a 0 cualquier valor negativo , al no tener un rango definido como la sigmoide, esta introduce no linealidad y permite en analisisde caracteristicas mas complejas.   La segunda capa es igual a la primera, pero con la mitad de la primera, se acostumbra a reducir las neuronas en subsecuentes capaz para enfocarse en detalles mas relevantes.   Por ultimo la capade salidas posee 10 neuronas y usa la funcion softmax, esta funcion esta especializada en calcular las probabilidades de que el dato de entrada pertenesca a una clase, de modod que todas sumen 1, cada neurona corresponde a una clase. Para la funcion de error se uso otra especializada en casos de clasificacion, en cuanto a por que se uso 2 capas ocultas, simplemente este es el numero que dio mejores reusltados sin causar overfitting"
      ],
      "metadata": {
        "id": "lsieon_Rvf5N"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E7IRv-5YwgQC"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}